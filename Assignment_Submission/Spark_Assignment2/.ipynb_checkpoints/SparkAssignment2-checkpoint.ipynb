{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b375edba",
   "metadata": {},
   "source": [
    "## Spark Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be78508",
   "metadata": {},
   "source": [
    "### Create Spark Session and Spark Context\n",
    "As first step create a spark session & spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887d561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.110.104.100:4040\n",
       "SparkContext available as 'sc' (version = 3.3.2, master = local[*], app id = local-1680109263066)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 13:01:06 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5f30e7a1\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Spark Assignment2\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4f2c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@46e24902\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62256b07",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8be07a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|  47|    1|    0|          363272|      7| null|       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|  62|    0|    0|          240276| 9.6875| null|       Q|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|  27|    0|    0|          315154| 8.6625| null|       S|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|  22|    1|    1|         3101298|12.2875| null|       S|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|  14|    0|    0|            7538|  9.225| null|       S|\n",
      "|        898|     3|Connolly, Miss. Kate|female|  30|    0|    0|          330972| 7.6292| null|       Q|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|  26|    1|    1|          248738|     29| null|       S|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|  18|    0|    0|            2657| 7.2292| null|       C|\n",
      "|        901|     3|Davies, Mr. John ...|  male|  21|    2|    0|       A/4 48871|  24.15| null|       S|\n",
      "|        902|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|  46|    0|    0|             694|     26| null|       S|\n",
      "|        904|     1|Snyder, Mrs. John...|female|  23|    1|    0|           21228|82.2667|  B45|       S|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|  63|    1|    0|           24065|     26| null|       S|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|  47|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|  24|    1|    0|   SC/PARIS 2167|27.7208| null|       C|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|  35|    0|    0|          233734|  12.35| null|       Q|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|  21|    0|    0|            2692|  7.225| null|       C|\n",
      "|        910|     3|Ilmakangas, Miss....|female|  27|    1|    0|STON/O2. 3101270|  7.925| null|       S|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|  45|    0|    0|            2696|  7.225| null|       C|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "testDf: org.apache.spark.sql.DataFrame = [PassengerId: string, Pclass: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testDf = spark.read.option(\"header\", \"true\").csv(\"test.csv\")\n",
    "testDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e69e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainDf: org.apache.spark.sql.DataFrame = [PassengerId: string, Survived: string ... 10 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainDf = spark.read.option(\"header\", \"true\").csv(\"train.csv\")\n",
    "trainDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c90fd",
   "metadata": {},
   "source": [
    "### Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "247eb839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainDfSelected: org.apache.spark.sql.DataFrame = [Survived: string, Pclass: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainDfSelected = trainDf.select(\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f746a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|summary|          Survived|            Pclass|   Sex|              Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|  count|               712|               712|   712|              712|               712|     712|\n",
      "|   mean|0.4044943820224719| 2.240168539325843|  null|29.64209269662921| 34.56725140449432|    null|\n",
      "| stddev|0.4911389472541192|0.8368543166903446|  null|14.49293290032352|52.938648174710906|    null|\n",
      "|    min|                 0|                 1|female|             0.42|                 0|       C|\n",
      "|    max|                 1|                 3|  male|                9|              93.5|       S|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_df_clean: org.apache.spark.sql.DataFrame = [Survived: string, Pclass: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val train_df_clean = trainDfSelected.na.drop()\n",
    "train_df_clean.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76976c",
   "metadata": {},
   "source": [
    "Fixing DataTypes of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e6395d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n",
       "train_df_clean_final: org.apache.spark.sql.DataFrame = [Survived: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "// Assuming df is your DataFrame and you want to change the data types of columns \"age\" and \"salary\"\n",
    "val train_df_clean_final = train_df_clean\n",
    "  .withColumn(\"Age\", col(\"Age\").cast(\"Double\"))\n",
    "  .withColumn(\"Fare\", col(\"Fare\").cast(\"Double\"))\n",
    "  .withColumn(\"Pclass\", col(\"Pclass\").cast(\"Integer\"))\n",
    "  .withColumn(\"Survived\", col(\"Survived\").cast(\"Integer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bed02f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_clean_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac6df4",
   "metadata": {},
   "source": [
    "Blank values filled with mean so that prediction is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b8da735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ageMeantrain: Double = 29.64209269662921\n",
       "fareMeantrain: Double = 34.56725140449432\n",
       "trainDFML: org.apache.spark.sql.DataFrame = [Survived: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageMeantrain = train_df_clean_final.agg(avg(\"Age\")).first()(0).asInstanceOf[Double]\n",
    "val fareMeantrain = train_df_clean_final.agg(avg(\"Fare\")).first()(0).asInstanceOf[Double]\n",
    "val trainDFML = train_df_clean_final.na.fill(ageMeantrain, Seq(\"Age\")).na.fill(fareMeantrain, Seq(\"Fare\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79729caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              Fare|\n",
      "+-------+------------------+\n",
      "|  count|               712|\n",
      "|   mean| 34.56725140449432|\n",
      "| stddev|52.938648174710906|\n",
      "|    min|               0.0|\n",
      "|    max|          512.3292|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDFML.describe(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4521bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testDfSelected: org.apache.spark.sql.DataFrame = [PassengerId: string, Pclass: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testDfSelected = testDf.select(\"PassengerId\", \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af170ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "|summary|       PassengerId|            Pclass|   Sex|               Age|             Fare|Embarked|\n",
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "|  count|               331|               331|   331|               331|              331|     331|\n",
      "|   mean|1100.2326283987916|2.1419939577039275|  null|30.181268882175228|40.98208731117823|    null|\n",
      "| stddev|122.91018015895622|0.8462507042885307|  null|14.104572594801617|61.22855822554924|    null|\n",
      "|    min|              1001|                 1|female|              0.17|                0|       C|\n",
      "|    max|               998|                 3|  male|                 9|             93.5|       S|\n",
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test_df_clean: org.apache.spark.sql.DataFrame = [PassengerId: string, Pclass: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test_df_clean = testDfSelected.na.drop()\n",
    "test_df_clean.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53856fb4",
   "metadata": {},
   "source": [
    "Fixing DataTypes of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "000a38f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n",
       "test_df_clean_final: org.apache.spark.sql.DataFrame = [PassengerId: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "// Assuming df is your DataFrame and you want to change the data types of columns \"age\" and \"salary\"\n",
    "val test_df_clean_final = test_df_clean\n",
    "  .withColumn(\"Age\", col(\"Age\").cast(\"Double\"))\n",
    "  .withColumn(\"Fare\", col(\"Fare\").cast(\"Double\"))\n",
    "  .withColumn(\"Pclass\", col(\"Pclass\").cast(\"Integer\"))\n",
    "  .withColumn(\"PassengerId\", col(\"PassengerId\").cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "335a85be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df_clean_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac378301",
   "metadata": {},
   "source": [
    "Blank values filled with mean so that prediction is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd75b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ageMean: Double = 30.181268882175228\n",
       "fareMean: Double = 40.98208731117823\n",
       "testDFML: org.apache.spark.sql.DataFrame = [PassengerId: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ageMean = test_df_clean_final.agg(avg(\"Age\")).first()(0).asInstanceOf[Double]\n",
    "val fareMean = test_df_clean_final.agg(avg(\"Fare\")).first()(0).asInstanceOf[Double]\n",
    "val testDFML = test_df_clean_final.na.fill(ageMean, Seq(\"Age\")).na.fill(fareMean, Seq(\"Fare\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb284bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "|summary|       PassengerId|            Pclass|   Sex|               Age|             Fare|Embarked|\n",
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "|  count|               331|               331|   331|               331|              331|     331|\n",
      "|   mean|1100.2326283987916|2.1419939577039275|  null|30.181268882175228|40.98208731117823|    null|\n",
      "| stddev|122.91018015895622|0.8462507042885307|  null|14.104572594801617|61.22855822554924|    null|\n",
      "|    min|               892|                 1|female|              0.17|              0.0|       C|\n",
      "|    max|              1307|                 3|  male|              76.0|         512.3292|       S|\n",
      "+-------+------------------+------------------+------+------------------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDFML.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b3fab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Fare|\n",
      "+-------+-----------------+\n",
      "|  count|              331|\n",
      "|   mean|40.98208731117823|\n",
      "| stddev|61.22855822554924|\n",
      "|    min|              0.0|\n",
      "|    max|         512.3292|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDFML.describe(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b67e8",
   "metadata": {},
   "source": [
    "We can see the mean Fare overall was 40.98 out of 331 people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b892c",
   "metadata": {},
   "source": [
    "Let's see if there's a difference between Male and Female Fares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6ed1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testMaleDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [PassengerId: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testMaleDf = testDFML.filter(testDf(\"Sex\") === \"male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "21529359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testFemaleDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [PassengerId: int, Pclass: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val testFemaleDf = testDFML.filter(testDf(\"Sex\") === \"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a021a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              Fare|\n",
      "+-------+------------------+\n",
      "|  count|               204|\n",
      "|   mean|31.688071078431378|\n",
      "| stddev|45.511592302124235|\n",
      "|    min|               0.0|\n",
      "|    max|           262.375|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testMaleDf.describe(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "93f226bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Fare|\n",
      "+-------+-----------------+\n",
      "|  count|              127|\n",
      "|   mean|55.91105826771652|\n",
      "| stddev|78.21154608341406|\n",
      "|    min|             6.95|\n",
      "|    max|         512.3292|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testFemaleDf.describe(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed4f2c",
   "metadata": {},
   "source": [
    "As we can see there are 204 males and the Mean Fare for \"Male\" is 31.68 and there are 152 females and the mean for \"Female\" is 55.91. We can say that Females paid more than males on an average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8770b8",
   "metadata": {},
   "source": [
    "### Prediction using Logistic Regression\n",
    "Logistic regression is a popular machine learning algorithm used for binary classification problems, where the goal is to predict a binary outcome, such as whether a passenger on the Titanic survived or not. Here are some reasons why logistic regression can be used for prediction on the Titanic dataset:\n",
    "\n",
    "Used Age, Class, Sex as variables for prediction\n",
    "\n",
    "Interpretability: Logistic regression produces interpretable results, meaning that the coefficients of the model can be used to determine the effect of each feature on the target variable. This can provide insight into which features are important for predicting survival on the Titanic.\n",
    "\n",
    "Handles categorical features: Logistic regression can handle categorical features, which are common in the Titanic dataset (e.g., sex, class,etc.).\n",
    "\n",
    "\n",
    "Overall, logistic regression is a good choice for binary classification problems, and can be a useful tool for predicting survival on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b56a148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{VectorAssembler, VectorIndexer, StringIndexer, OneHotEncoder}\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{VectorAssembler, VectorIndexer, StringIndexer, OneHotEncoder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a347a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex_indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_3a0fe502b83c\n",
       "sex_encoder: org.apache.spark.ml.feature.OneHotEncoder = oneHotEncoder_c09aa4d5850e\n",
       "embarked_indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_ae1fe0983e9f\n",
       "embarked_encoder: org.apache.spark.ml.feature.OneHotEncoder = oneHotEncoder_05733b8f1c12\n"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// StringIndexer\n",
    "val sex_indexer = new StringIndexer()\n",
    "  .setInputCol(\"Sex\")\n",
    "  .setOutputCol(\"SexIndex\")\n",
    "\n",
    "// OneHotEncoder\n",
    "val sex_encoder = new OneHotEncoder()\n",
    "  .setInputCol(\"SexIndex\")\n",
    "  .setOutputCol(\"SexVec\")\n",
    "\n",
    "// StringIndexer\n",
    "val embarked_indexer = new StringIndexer()\n",
    "  .setInputCol(\"Embarked\")\n",
    "  .setOutputCol(\"EmbarkedIndex\")\n",
    "\n",
    "// OneHotEncoder\n",
    "val embarked_encoder = new OneHotEncoder()\n",
    "  .setInputCol(\"EmbarkedIndex\")\n",
    "  .setOutputCol(\"EmbarkedVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0bb25b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_5c5d956e5568, handleInvalid=error, numInputCols=5\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"Pclass\", \"SexVec\", \"Age\", \"Fare\", \"EmbarkedVec\"))\n",
    "  .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c514f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "logistic_reg_model: org.apache.spark.ml.classification.LogisticRegression = logreg_d2c96b97c4fe\n"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "\n",
    "val logistic_reg_model = new LogisticRegression()\n",
    ".setFeaturesCol(\"features\")\n",
    ".setLabelCol(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "528f1949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_258aa583194f\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    ".setStages(Array(sex_indexer, embarked_indexer, sex_encoder, embarked_encoder,\n",
    "assembler, logistic_reg_model))\n",
    "\n",
    "//val pipelineModel = pipeline.fit(trainingData) // assuming you have a trainingData DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa3e4182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_fit: org.apache.spark.ml.PipelineModel = pipeline_258aa583194f\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model_fit: PipelineModel = pipeline.fit(trainDFML)\n",
    "//val pipelineModel = pipeline.fit(train_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37603892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [PassengerId: int, Pclass: int ... 12 more fields]\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model_fit.transform(testDFML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad2defec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerId|prediction|\n",
      "+-----------+----------+\n",
      "|        892|       0.0|\n",
      "|        893|       0.0|\n",
      "|        894|       0.0|\n",
      "|        895|       0.0|\n",
      "|        896|       1.0|\n",
      "|        897|       0.0|\n",
      "|        898|       0.0|\n",
      "|        899|       0.0|\n",
      "|        900|       1.0|\n",
      "|        901|       0.0|\n",
      "|        903|       0.0|\n",
      "|        904|       1.0|\n",
      "|        905|       0.0|\n",
      "|        906|       1.0|\n",
      "|        907|       1.0|\n",
      "|        908|       0.0|\n",
      "|        909|       0.0|\n",
      "|        910|       1.0|\n",
      "|        911|       1.0|\n",
      "|        912|       0.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prediction_results: org.apache.spark.sql.DataFrame = [PassengerId: int, prediction: double]\n"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prediction_results = results.select(\"PassengerId\", \"prediction\")\n",
    "prediction_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec131e5",
   "metadata": {},
   "source": [
    "### Prediction to CSV file (import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "328d01df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.DataFrame\n",
       "outputPath: String = /Users/anirudhajoshi/Documents/NEU_Work/NEU_Spring2023_Work/Big_Data_Scala/Spark_Assignment2/prediction_result.csv\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "// assume df is your DataFrame\n",
    "val outputPath = \"/Users/anirudhajoshi/Documents/NEU_Work/NEU_Spring2023_Work/Big_Data_Scala/Spark_Assignment2/prediction_result.csv\"\n",
    "\n",
    "prediction_results.write\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", \"true\") // write header row\n",
    "  .option(\"delimiter\", \",\") // set delimiter to comma\n",
    "  .mode(\"overwrite\") // overwrite if file already exists\n",
    "  .save(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c069ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
